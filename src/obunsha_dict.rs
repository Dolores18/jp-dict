use rusqlite::{Connection, Result, params};
use serde::{Deserialize, Serialize};
use scraper::Html;

/// æ—ºæ–‡ç¤¾å›½èªè¾å…¸è¯æ¡ç»“æ„ (Obunsha Kokugo Dictionary Entry)
/// åŸºäºMDXæ ¼å¼çš„ä¸“ä¸šæ—¥è¯­è¯å…¸æ•°æ®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ObunshaDictEntry {
    pub id: Option<i64>,
    /// è¯æ¡ID - æ¥æºäºMDXçš„data-id
    pub data_id: String,
    /// è¯æ¡ç±»å‹ - æ¥æºäºMDXçš„data-type  
    pub data_type: String,
    /// è¯æ¡æ ‡é¢˜ - ä»MDXå…³é”®è¯æå–çš„æ ‡é¢˜
    pub headword: String,
    /// å‡åè¯»éŸ³ - æå–çš„å‡åéƒ¨åˆ†
    pub kana_reading: Option<String>,
    /// æ±‰å­—è¡¨è®° - æå–çš„æ±‰å­—éƒ¨åˆ†
    pub kanji_writing: Option<String>,
    /// è¯æ€§ä¿¡æ¯ - å¦‚"è‡ªäº”"ç­‰è¯­æ³•ä¿¡æ¯
    pub part_of_speech: Option<String>,
    /// æ´»ç”¨å½¢ - åŠ¨è¯ã€å½¢å®¹è¯çš„å˜åŒ–å½¢å¼
    pub conjugation: Option<String>,
    /// è¯æ¡å®šä¹‰ - å®Œæ•´çš„HTMLå®šä¹‰å†…å®¹
    pub definition_html: String,
    /// çº¯æ–‡æœ¬å®šä¹‰ - å»é™¤HTMLæ ‡ç­¾çš„çº¯æ–‡æœ¬ç‰ˆæœ¬
    pub definition_text: String,
    /// åŸå§‹MDXå†…å®¹ - ä¿ç•™å®Œæ•´çš„åŸå§‹æ•°æ®
    pub raw_mdx_content: String,
}

/// æ—ºæ–‡ç¤¾å›½èªè¾å…¸æ•°æ®åº“ç®¡ç†
pub struct ObunshaDictDatabase {
    conn: Connection,
}

impl ObunshaDictDatabase {
    /// åˆ›å»ºæ–°çš„æ•°æ®åº“è¿æ¥
    pub fn new(db_path: &str) -> Result<Self> {
        let conn = Connection::open(db_path)?;
        Ok(ObunshaDictDatabase { conn })
    }

    /// åˆå§‹åŒ–æ—ºæ–‡ç¤¾å›½èªè¾å…¸è¡¨
    /// è¡¨å: obunsha_kokugo_dict (æ—ºæ–‡ç¤¾å›½èªè¾å…¸)
    pub fn initialize(&self) -> Result<()> {
        self.conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS obunsha_kokugo_dict (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                data_id TEXT NOT NULL UNIQUE,               -- MDXè¯æ¡ID
                data_type TEXT NOT NULL,                    -- MDXè¯æ¡ç±»å‹
                headword TEXT NOT NULL,                     -- è¯æ¡æ ‡é¢˜
                kana_reading TEXT,                          -- å‡åè¯»éŸ³
                kanji_writing TEXT,                         -- æ±‰å­—è¡¨è®°
                part_of_speech TEXT,                        -- è¯æ€§ä¿¡æ¯
                conjugation TEXT,                           -- æ´»ç”¨å½¢
                definition_html TEXT NOT NULL,              -- HTMLå®šä¹‰
                definition_text TEXT NOT NULL,              -- çº¯æ–‡æœ¬å®šä¹‰
                raw_mdx_content TEXT NOT NULL,              -- åŸå§‹MDXå†…å®¹
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
            "#,
            [],
        )?;

        // åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
        self.conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_headword ON obunsha_kokugo_dict(headword)",
            [],
        )?;

        self.conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_kana_reading ON obunsha_kokugo_dict(kana_reading)",
            [],
        )?;

        self.conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_data_id ON obunsha_kokugo_dict(data_id)",
            [],
        )?;

        println!("âœ… æ—ºæ–‡ç¤¾å›½èªè¾å…¸è¡¨å·²åˆå§‹åŒ–");
        Ok(())
    }

    /// æ’å…¥å•ä¸ªè¯æ¡
    pub fn insert_entry(&self, entry: &ObunshaDictEntry) -> Result<i64> {
        let mut stmt = self.conn.prepare(
            r#"
            INSERT INTO obunsha_kokugo_dict (
                data_id, data_type, headword, kana_reading, kanji_writing,
                part_of_speech, conjugation, definition_html, definition_text, raw_mdx_content
            ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)
            "#,
        )?;

        let row_id = stmt.insert(params![
            entry.data_id,
            entry.data_type,
            entry.headword,
            entry.kana_reading,
            entry.kanji_writing,
            entry.part_of_speech,
            entry.conjugation,
            entry.definition_html,
            entry.definition_text,
            entry.raw_mdx_content,
        ])?;

        Ok(row_id)
    }

    /// æ‰¹é‡æ’å…¥è¯æ¡
    pub fn insert_entries_batch(&self, entries: &[ObunshaDictEntry]) -> Result<usize> {
        let tx = self.conn.unchecked_transaction()?;
        
        {
            let mut stmt = tx.prepare(
                r#"
                INSERT OR REPLACE INTO obunsha_kokugo_dict (
                    data_id, data_type, headword, kana_reading, kanji_writing,
                    part_of_speech, conjugation, definition_html, definition_text, raw_mdx_content
                ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)
                "#,
            )?;

            for entry in entries {
                stmt.execute(params![
                    entry.data_id,
                    entry.data_type,
                    entry.headword,
                    entry.kana_reading,
                    entry.kanji_writing,
                    entry.part_of_speech,
                    entry.conjugation,
                    entry.definition_html,
                    entry.definition_text,
                    entry.raw_mdx_content,
                ])?;
            }
        }

        tx.commit()?;
        println!("âœ… æˆåŠŸæ’å…¥ {} æ¡è¯æ¡", entries.len());
        Ok(entries.len())
    }

    /// æ ¹æ®æ ‡é¢˜æŸ¥è¯¢è¯æ¡ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼Œä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰
    pub fn search_by_headword(&self, headword: &str) -> Result<Vec<ObunshaDictEntry>> {
        let mut stmt = self.conn.prepare(
            "SELECT * FROM obunsha_kokugo_dict WHERE headword LIKE ?1 ORDER BY headword"
        )?;

        let entry_iter = stmt.query_map([format!("%{}%", headword)], |row| {
            Ok(ObunshaDictEntry {
                id: Some(row.get(0)?),
                data_id: row.get(1)?,
                data_type: row.get(2)?,
                headword: row.get(3)?,
                kana_reading: row.get(4)?,
                kanji_writing: row.get(5)?,
                part_of_speech: row.get(6)?,
                conjugation: row.get(7)?,
                definition_html: row.get(8)?,
                definition_text: row.get(9)?,
                raw_mdx_content: row.get(10)?,
            })
        })?;

        let mut entries = Vec::new();
        for entry in entry_iter {
            entries.push(entry?);
        }

        Ok(entries)
    }

    /// æ ¹æ®å‡åç²¾ç¡®æœç´¢ï¼ˆå…¨ç­‰åŒ¹é…ï¼‰
    pub fn search_by_kana_exact(&self, kana: &str) -> Result<Vec<ObunshaDictEntry>> {
        let mut stmt = self.conn.prepare(
            "SELECT * FROM obunsha_kokugo_dict WHERE kana_reading = ?1 ORDER BY headword"
        )?;

        let entry_iter = stmt.query_map([kana], |row| {
            Ok(ObunshaDictEntry {
                id: Some(row.get(0)?),
                data_id: row.get(1)?,
                data_type: row.get(2)?,
                headword: row.get(3)?,
                kana_reading: row.get(4)?,
                kanji_writing: row.get(5)?,
                part_of_speech: row.get(6)?,
                conjugation: row.get(7)?,
                definition_html: row.get(8)?,
                definition_text: row.get(9)?,
                raw_mdx_content: row.get(10)?,
            })
        })?;

        let mut entries = Vec::new();
        for entry in entry_iter {
            entries.push(entry?);
        }

        Ok(entries)
    }

    /// æ ¹æ®æ±‰å­—æ™ºèƒ½æœç´¢ï¼ˆåŒæ—¶è¿›è¡Œç²¾ç¡®åŒ¹é…å’ŒåŒ…å«åŒ¹é…ï¼‰
    pub fn search_by_kanji_smart(&self, kanji: &str) -> Result<Vec<ObunshaDictEntry>> {
        let mut entries = Vec::new();
        let mut seen_ids = std::collections::HashSet::new();

        // é¦–å…ˆè¿›è¡Œç²¾ç¡®åŒ¹é…
        let mut stmt = self.conn.prepare(
            "SELECT * FROM obunsha_kokugo_dict WHERE kanji_writing = ?1 ORDER BY headword"
        )?;

        let entry_iter = stmt.query_map([kanji], |row| {
            Ok(ObunshaDictEntry {
                id: Some(row.get(0)?),
                data_id: row.get(1)?,
                data_type: row.get(2)?,
                headword: row.get(3)?,
                kana_reading: row.get(4)?,
                kanji_writing: row.get(5)?,
                part_of_speech: row.get(6)?,
                conjugation: row.get(7)?,
                definition_html: row.get(8)?,
                definition_text: row.get(9)?,
                raw_mdx_content: row.get(10)?,
            })
        })?;

        for entry in entry_iter {
            let entry = entry?;
            seen_ids.insert(entry.data_id.clone());
            entries.push(entry);
        }

        // ç„¶åè¿›è¡ŒLIKEæœç´¢ï¼ˆæŸ¥æ‰¾å¸¦ç‚¹å·çš„å¤šé‡è¡¨è®°ï¼‰
        let mut stmt = self.conn.prepare(
            "SELECT * FROM obunsha_kokugo_dict WHERE kanji_writing LIKE ?1 ORDER BY headword"
        )?;

        let entry_iter = stmt.query_map([format!("%{}%", kanji)], |row| {
            Ok(ObunshaDictEntry {
                id: Some(row.get(0)?),
                data_id: row.get(1)?,
                data_type: row.get(2)?,
                headword: row.get(3)?,
                kana_reading: row.get(4)?,
                kanji_writing: row.get(5)?,
                part_of_speech: row.get(6)?,
                conjugation: row.get(7)?,
                definition_html: row.get(8)?,
                definition_text: row.get(9)?,
                raw_mdx_content: row.get(10)?,
            })
        })?;

        for entry_result in entry_iter {
            let entry = entry_result?;
            // é¿å…é‡å¤æ·»åŠ å·²ç»åœ¨ç²¾ç¡®åŒ¹é…ä¸­æ‰¾åˆ°çš„è¯æ¡
            if !seen_ids.contains(&entry.data_id) {
                // åº”ç”¨å±‚è¿‡æ»¤ï¼šæ£€æŸ¥æ˜¯å¦çœŸçš„åŒ¹é…ï¼ˆæ”¯æŒç‚¹å·åˆ†å‰²çš„å¤šé‡è¡¨è®°ï¼‰
                if let Some(ref kanji_writing) = entry.kanji_writing {
                    if kanji_writing.split('Â·').any(|part| part == kanji) {
                        entries.push(entry);
                    }
                }
            }
        }

        Ok(entries)
    }

    /// è·å–è¡¨çš„ç»Ÿè®¡ä¿¡æ¯
    pub fn get_stats(&self) -> Result<(i64, i64)> {
        let count: i64 = self.conn.query_row(
            "SELECT COUNT(*) FROM obunsha_kokugo_dict",
            [],
            |row| row.get(0)
        )?;

        let unique_headwords: i64 = self.conn.query_row(
            "SELECT COUNT(DISTINCT headword) FROM obunsha_kokugo_dict",
            [],
            |row| row.get(0)
        )?;

        Ok((count, unique_headwords))
    }

    /// ä»æ¸…ç†åçš„æ•°æ®æ–‡ä»¶è§£æå¹¶å¯¼å…¥æ‰€æœ‰è¯æ¡
    pub fn import_from_cleaned_data(&self, cleaned_data_path: &str) -> Result<usize, Box<dyn std::error::Error>> {
        use std::fs::File;
        use std::io::{BufRead, BufReader};

        println!("ğŸš€ å¼€å§‹ä»æ¸…ç†æ•°æ®å¯¼å…¥è¯æ¡: {}", cleaned_data_path);

        let file = File::open(cleaned_data_path)?;
        let reader = BufReader::new(file);
        let mut lines = reader.lines();

        let mut entries = Vec::new();
        let mut current_title: Option<String> = None;
        let mut processed_count = 0;

        while let Some(line_result) = lines.next() {
            let line = line_result?;
            
            if line.trim().is_empty() {
                // ç©ºè¡Œè¡¨ç¤ºè¯æ¡ç»“æŸï¼Œé‡ç½®çŠ¶æ€
                current_title = None;
                continue;
            }

            if line.contains("<link rel=\"stylesheet\"") {
                // è¿™æ˜¯HTMLå†…å®¹è¡Œ
                if let Some(title) = current_title.take() {
                    // è§£æè¿™ä¸ªè¯æ¡
                    if let Some(entry) = self.parse_entry_from_html(&title, &line) {
                        entries.push(entry);
                        processed_count += 1;

                        // æ¯1000æ¡æ‰¹é‡æ’å…¥ä¸€æ¬¡
                        if entries.len() >= 1000 {
                            self.insert_entries_batch(&entries)?;
                            entries.clear();
                            println!("âœ… å·²å¯¼å…¥ {} æ¡è¯æ¡", processed_count);
                        }
                    }
                }
            } else {
                // è¿™æ˜¯æ ‡é¢˜è¡Œ
                current_title = Some(line);
            }
        }

        // æ’å…¥å‰©ä½™çš„è¯æ¡
        if !entries.is_empty() {
            self.insert_entries_batch(&entries)?;
        }

        println!("ğŸ‰ å¯¼å…¥å®Œæˆï¼å…±å¤„ç† {} æ¡è¯æ¡", processed_count);
        Ok(processed_count)
    }

    /// ä»HTMLè§£æå•ä¸ªè¯æ¡
    fn parse_entry_from_html(&self, title: &str, html: &str) -> Option<ObunshaDictEntry> {
        use scraper::{Html, Selector};

        let document = Html::parse_fragment(html);
        
        // æå–data-id
        let container_selector = Selector::parse("container").ok()?;
        let container = document.select(&container_selector).next()?;
        let data_id = container.value().attr("data-id")?.to_string();
        let data_type = container.value().attr("data-type").unwrap_or("unknown").to_string();

        // CSSé€‰æ‹©å™¨
        let kana_selector = Selector::parse(".headword_kana").ok()?;
        let kanji_selector = Selector::parse(".headword_hyouki").ok()?;
        let ryaku_selector = Selector::parse(".headword_ryaku").ok()?;
        let pos_selector = Selector::parse(".pos_s").ok()?;
        let katsuyo_selector = Selector::parse(".katsuyo").ok()?;

        let mut kana_reading: Option<String> = None;
        let mut kanji_writing: Option<String> = None;
        let mut part_of_speech: Option<String> = None;
        let mut conjugation: Option<String> = None;

        // ä¼˜å…ˆä»headlineï¼ˆtitleï¼‰è§£æå‡åå’Œæ±‰å­—
        if let Some((kana, kanji)) = self.parse_headline(title) {
            kana_reading = Some(kana);
            kanji_writing = Some(kanji);
        } else {
        }

        // å¦‚æœä»headlineè§£æå¤±è´¥ï¼Œå†ä»HTMLä¸­é€‰æ‹©å™¨æå–
        if kana_reading.is_none() {
            if let Some(kana_element) = document.select(&kana_selector).next() {
                let kana_text = kana_element.text().collect::<String>();
                let cleaned_kana = self.clean_kana_text(&kana_text);
                if !cleaned_kana.is_empty() {
                    kana_reading = Some(cleaned_kana);
                }
            }
        }

        if kanji_writing.is_none() {
            if let Some(kanji_element) = document.select(&kanji_selector).next() {
                let kanji_text = kanji_element.text().collect::<String>();
                let cleaned_kanji = self.clean_kanji_text(&kanji_text);
                if !cleaned_kanji.is_empty() {
                    kanji_writing = Some(cleaned_kanji);
                }
            }
        }

        // å¯¹äºè‹±æ–‡ç¼©å†™è¯æ¡ï¼Œæå–ryakuä½œä¸ºå‡åè¯»éŸ³
        if kana_reading.is_none() {
            if let Some(ryaku_element) = document.select(&ryaku_selector).next() {
                let ryaku_text = ryaku_element.text().collect::<String>();
                let cleaned_ryaku = self.clean_kana_text(&ryaku_text);
                if !cleaned_ryaku.is_empty() {
                    kana_reading = Some(cleaned_ryaku);
                }
            }
        }

        // æå–è¯æ€§ä¿¡æ¯
        if let Some(pos_element) = document.select(&pos_selector).next() {
            let pos_text = pos_element.text().collect::<String>().trim().to_string();
            if !pos_text.is_empty() {
                part_of_speech = Some(pos_text);
            }
        }

        // æå–æ´»ç”¨å½¢
        if let Some(katsuyo_element) = document.select(&katsuyo_selector).next() {
            let katsuyo_text = katsuyo_element.text().collect::<String>().trim().to_string();
            if !katsuyo_text.is_empty() {
                conjugation = Some(katsuyo_text);
            }
        }

        // æå–çº¯æ–‡æœ¬å®šä¹‰
        let definition_text = self.extract_definition_text(&document);

        Some(ObunshaDictEntry {
            id: None,
            data_id,
            data_type,
            headword: title.to_string(),
            kana_reading,
            kanji_writing,
            part_of_speech,
            conjugation,
            definition_html: html.to_string(),
            definition_text,
            raw_mdx_content: format!("{}\n{}", title, html),
        })
    }

    /// ä»headlineè§£æå‡åå’Œæ±‰å­—
    fn parse_headline(&self, headline: &str) -> Option<(String, String)> {
        let headline = headline.trim();
        
        // æ£€æŸ¥æ˜¯å¦åŒ…å«ã€ã€‘æ‹¬å·æ ¼å¼ï¼šå‡åã€æ±‰å­—ã€‘
        if let Some(start) = headline.find('ã€') {
            if let Some(end) = headline.find('ã€‘') {
                if start < end {
                    // ä½¿ç”¨chars()è¿­ä»£å™¨æ¥æ­£ç¡®å¤„ç†ä¸­æ–‡å­—ç¬¦
                    let chars: Vec<char> = headline.chars().collect();
                    
                    // å°†å­—èŠ‚ç´¢å¼•è½¬æ¢ä¸ºå­—ç¬¦ç´¢å¼•
                    let start_char = headline[..start].chars().count();
                    let end_char = headline[..end].chars().count();
                    
                    if start_char < end_char && start_char < chars.len() && end_char < chars.len() {
                        let kana_part: String = chars[..start_char].iter().collect();
                        let kanji_part: String = chars[start_char + 1..end_char].iter().collect();
                        
                        // å‡åéƒ¨åˆ†ä¸èƒ½ä¸ºç©ºï¼Œæ±‰å­—éƒ¨åˆ†å¯ä»¥ä¸ºç©ºï¼ˆå¦‚ï¼šã°ã€ã€‘ï¼‰
                        if !kana_part.is_empty() {
                            return Some((kana_part, kanji_part));
                        }
                    }
                }
            }
        }
        
        // å¦‚æœæ²¡æœ‰æ‹¬å·ï¼Œæ£€æŸ¥æ˜¯å¦åªæœ‰å‡å
        if !headline.is_empty() {
            // æ£€æŸ¥æ˜¯å¦åŒ…å«æ±‰å­—
            let has_kanji = headline.chars().any(|c| {
                c >= '\u{4e00}' && c <= '\u{9fff}' // CJKç»Ÿä¸€æ±‰å­—
            });
            
            if !has_kanji {
                // åªæœ‰å‡åçš„æƒ…å†µ
                return Some((headline.to_string(), String::new()));
            }
        }
        
        None
    }

    /// æ¸…ç†å‡åæ–‡æœ¬ï¼Œå»é™¤ç‰¹æ®Šç¬¦å·å’ŒHTMLæ ‡ç­¾
    fn clean_kana_text(&self, text: &str) -> String {
        let mut result = String::new();
        
        for ch in text.chars() {
            match ch {
                // ä¿ç•™å¹³å‡å
                '\u{3040}'..='\u{309f}' => result.push(ch),
                // ä¿ç•™ç‰‡å‡å
                '\u{30a0}'..='\u{30ff}' => result.push(ch),
                // ä¿ç•™ç‰‡å‡åé•¿éŸ³ç¬¦å·
                'ãƒ¼' => result.push(ch),
                // ä¿ç•™è‹±æ–‡å’Œæ•°å­—ï¼ˆç”¨äºè‹±æ–‡ç¼©å†™è¯æ¡ï¼‰
                _ if ch.is_ascii_alphanumeric() => result.push(ch),
                // å¯¹äºè‹±æ–‡è¯æ¡ï¼Œä¿ç•™è¿å­—ç¬¦å’Œä¸‹åˆ’çº¿
                '-' | '_' if text.chars().any(|c| c.is_ascii_alphabetic()) => result.push(ch),
                // è¿‡æ»¤æ‰æ‰€æœ‰å…¶ä»–ç¬¦å·ï¼ŒåŒ…æ‹¬æ—¥è¯­è¯æ¡ä¸­çš„ASCIIè¿å­—ç¬¦
                _ => {}
            }
        }
        
        result.trim().to_string()
    }

    /// æ¸…ç†æ±‰å­—æ–‡æœ¬ï¼Œå»é™¤æ ‡è®°ç¬¦å·
    fn clean_kanji_text(&self, text: &str) -> String {
        let mut result = String::new();
        
        for ch in text.chars() {
            match ch {
                // ä¿ç•™æ±‰å­— (CJKç»Ÿä¸€æ±‰å­—)
                '\u{4e00}'..='\u{9fff}' => result.push(ch),
                // ä¿ç•™å¹³å‡å
                '\u{3040}'..='\u{309f}' => result.push(ch),
                // ä¿ç•™ç‰‡å‡å
                '\u{30a0}'..='\u{30ff}' => result.push(ch),
                // ä¿ç•™ä¸€äº›åŸºæœ¬ç¬¦å·
                'ãƒ»' | 'â€§' | 'Â·' | '-' | 'ãƒ¼' => result.push(ch),
                // è¿‡æ»¤æ‰æ ‡è®°ç¬¦å·
                'ã€' | 'ã€‘' | 'â—‡' | 'â–³' | 'â–½' | 'â–²' | 'â–¼' | 'â—‹' | 'â—' | 'â—¯' | 
                'â–¡' | 'â– ' | 'â–¢' | 'â–£' | 'â—†' | 'â€»' | 'ï¼Š' | 'â˜†' | 'â˜…' => {
                    // è·³è¿‡è¿™äº›æ ‡è®°ç¬¦å·
                },
                // ä¿ç•™å…¶ä»–å¯èƒ½æœ‰ç”¨çš„å­—ç¬¦ï¼ˆå¦‚è‹±æ–‡ã€æ•°å­—ï¼‰
                _ if ch.is_alphanumeric() => result.push(ch),
                _ => {} // è·³è¿‡å…¶ä»–ç‰¹æ®Šç¬¦å·
            }
        }
        
        result.trim().to_string()
    }

    /// æå–å®šä¹‰çš„çº¯æ–‡æœ¬å†…å®¹
    fn extract_definition_text(&self, document: &Html) -> String {
        use scraper::Selector;

        let meaning_selectors = [
            ".mean_normal",
            ".mean_lv_2", 
            ".mean_lv_1",
            ".mean_no_1",
            ".mean_no_2", 
            ".mean_no_3",
        ];
        
        let mut meanings = Vec::new();
        
        for selector_str in &meaning_selectors {
            if let Ok(selector) = Selector::parse(selector_str) {
                for element in document.select(&selector) {
                    let text = element.text().collect::<Vec<_>>().join("");
                    let cleaned_text = text.trim();
                    if !cleaned_text.is_empty() {
                        meanings.push(cleaned_text.to_string());
                    }
                }
            }
        }
        
        if meanings.is_empty() {
            // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šçš„é‡Šä¹‰å…ƒç´ ï¼Œæå–æ‰€æœ‰æ–‡æœ¬
            document.root_element().text().collect::<String>().trim().to_string()
        } else {
            meanings.join(" ")
        }
    }
} 